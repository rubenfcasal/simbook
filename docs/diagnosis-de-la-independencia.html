<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>B.2 Diagnosis de la independencia | Simulación Estadística</title>
  <meta name="description" content="Apuntes de la asignatura de Simulación Estadística del Máster en Técnicas Estadísticas." />
  <meta name="generator" content="bookdown 0.18 and GitBook 2.6.7" />

  <meta property="og:title" content="B.2 Diagnosis de la independencia | Simulación Estadística" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Apuntes de la asignatura de Simulación Estadística del Máster en Técnicas Estadísticas." />
  <meta name="github-repo" content="rubenfcasal/simbook" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="B.2 Diagnosis de la independencia | Simulación Estadística" />
  
  <meta name="twitter:description" content="Apuntes de la asignatura de Simulación Estadística del Máster en Técnicas Estadísticas." />
  

<meta name="author" content="Rubén Fernández Casal (ruben.fcasal@udc.es), Ricardo Cao (rcao@udc.es)" />


<meta name="date" content="2020-04-21" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="gof.html"/>
<link rel="next" href="contrastes-específicos-para-generadores-aleatorios.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Simulación Estadística</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Prólogo</a></li>
<li class="chapter" data-level="1" data-path="cap1.html"><a href="cap1.html"><i class="fa fa-check"></i><b>1</b> Introducción a la simulación</a><ul>
<li class="chapter" data-level="1.1" data-path="conceptos-básicos.html"><a href="conceptos-básicos.html"><i class="fa fa-check"></i><b>1.1</b> Conceptos básicos</a><ul>
<li class="chapter" data-level="1.1.1" data-path="conceptos-básicos.html"><a href="conceptos-básicos.html#ventajas-e-inconvenientes-de-la-simulación"><i class="fa fa-check"></i><b>1.1.1</b> Ventajas e inconvenientes de la simulación</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="generación-de-números-pseudoaleatorios.html"><a href="generación-de-números-pseudoaleatorios.html"><i class="fa fa-check"></i><b>1.2</b> Generación de números (pseudo)aleatorios</a></li>
<li class="chapter" data-level="1.3" data-path="números-aleatorios-puros.html"><a href="números-aleatorios-puros.html"><i class="fa fa-check"></i><b>1.3</b> Números aleatorios puros</a><ul>
<li class="chapter" data-level="1.3.1" data-path="números-aleatorios-puros.html"><a href="números-aleatorios-puros.html#inconvenientes"><i class="fa fa-check"></i><b>1.3.1</b> Inconvenientes:</a></li>
<li class="chapter" data-level="1.3.2" data-path="números-aleatorios-puros.html"><a href="números-aleatorios-puros.html#alternativas"><i class="fa fa-check"></i><b>1.3.2</b> Alternativas:</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="números-pseudoaleatorios.html"><a href="números-pseudoaleatorios.html"><i class="fa fa-check"></i><b>1.4</b> Números pseudoaleatorios</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="cap2.html"><a href="cap2.html"><i class="fa fa-check"></i><b>2</b> Números aleatorios en R</a><ul>
<li class="chapter" data-level="2.1" data-path="opciones.html"><a href="opciones.html"><i class="fa fa-check"></i><b>2.1</b> Opciones</a></li>
<li class="chapter" data-level="2.2" data-path="paquetes-de-r.html"><a href="paquetes-de-r.html"><i class="fa fa-check"></i><b>2.2</b> Paquetes de R</a></li>
<li class="chapter" data-level="2.3" data-path="ejercicios.html"><a href="ejercicios.html"><i class="fa fa-check"></i><b>2.3</b> Ejercicios</a></li>
<li class="chapter" data-level="2.4" data-path="tiempo-de-cpu.html"><a href="tiempo-de-cpu.html"><i class="fa fa-check"></i><b>2.4</b> Tiempo de CPU</a><ul>
<li class="chapter" data-level="2.4.1" data-path="tiempo-de-cpu.html"><a href="tiempo-de-cpu.html#utilidades-tiempo-de-cpu"><i class="fa fa-check"></i><b>2.4.1</b> Utilidades tiempo de CPU</a></li>
<li class="chapter" data-level="2.4.2" data-path="tiempo-de-cpu.html"><a href="tiempo-de-cpu.html#paquetes-de-r-1"><i class="fa fa-check"></i><b>2.4.2</b> Paquetes de R</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="cap3.html"><a href="cap3.html"><i class="fa fa-check"></i><b>3</b> Generación de números pseudoaleatorios con distribución uniforme</a><ul>
<li class="chapter" data-level="3.1" data-path="gen-cong.html"><a href="gen-cong.html"><i class="fa fa-check"></i><b>3.1</b> Generadores congruenciales (lineales)</a><ul>
<li class="chapter" data-level="3.1.1" data-path="gen-cong.html"><a href="gen-cong.html#otros-generadores"><i class="fa fa-check"></i><b>3.1.1</b> Otros generadores</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="calgen.html"><a href="calgen.html"><i class="fa fa-check"></i><b>3.2</b> Análisis de la calidad de un generador</a><ul>
<li class="chapter" data-level="3.2.1" data-path="calgen.html"><a href="calgen.html#repetición-de-contrastes"><i class="fa fa-check"></i><b>3.2.1</b> Repetición de contrastes</a></li>
<li class="chapter" data-level="3.2.2" data-path="calgen.html"><a href="calgen.html#baterias"><i class="fa fa-check"></i><b>3.2.2</b> Baterías de contrastes</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="ejercicios-1.html"><a href="ejercicios-1.html"><i class="fa fa-check"></i><b>3.3</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="cap4.html"><a href="cap4.html"><i class="fa fa-check"></i><b>4</b> Análisis de resultados de simulación</a><ul>
<li class="chapter" data-level="4.1" data-path="convergencia.html"><a href="convergencia.html"><i class="fa fa-check"></i><b>4.1</b> Convergencia</a><ul>
<li class="chapter" data-level="4.1.1" data-path="convergencia.html"><a href="convergencia.html#detección-de-problemas-de-convergencia"><i class="fa fa-check"></i><b>4.1.1</b> Detección de problemas de convergencia</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="estimación-de-la-precisión.html"><a href="estimación-de-la-precisión.html"><i class="fa fa-check"></i><b>4.2</b> Estimación de la precisión</a></li>
<li class="chapter" data-level="4.3" data-path="teorema-central-del-límite.html"><a href="teorema-central-del-límite.html"><i class="fa fa-check"></i><b>4.3</b> Teorema central del límite</a></li>
<li class="chapter" data-level="4.4" data-path="determinación-del-número-de-generaciones.html"><a href="determinación-del-número-de-generaciones.html"><i class="fa fa-check"></i><b>4.4</b> Determinación del número de generaciones</a></li>
<li class="chapter" data-level="4.5" data-path="el-problema-de-la-dependencia.html"><a href="el-problema-de-la-dependencia.html"><i class="fa fa-check"></i><b>4.5</b> El problema de la dependencia</a><ul>
<li class="chapter" data-level="4.5.1" data-path="el-problema-de-la-dependencia.html"><a href="el-problema-de-la-dependencia.html#periodo-de-calentamiento"><i class="fa fa-check"></i><b>4.5.1</b> Periodo de calentamiento</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="observaciones.html"><a href="observaciones.html"><i class="fa fa-check"></i><b>4.6</b> Observaciones</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="simulación-de-variables-continuas.html"><a href="simulación-de-variables-continuas.html"><i class="fa fa-check"></i><b>5</b> Simulación de variables continuas</a><ul>
<li class="chapter" data-level="5.1" data-path="método-de-inversión.html"><a href="método-de-inversión.html"><i class="fa fa-check"></i><b>5.1</b> Método de inversión</a><ul>
<li class="chapter" data-level="5.1.1" data-path="método-de-inversión.html"><a href="método-de-inversión.html#algunas-distribuciones-que-pueden-simularse-por-el-método-de-inversión"><i class="fa fa-check"></i><b>5.1.1</b> Algunas distribuciones que pueden simularse por el método de inversión</a></li>
<li class="chapter" data-level="5.1.2" data-path="método-de-inversión.html"><a href="método-de-inversión.html#ventajas-e-inconvenientes"><i class="fa fa-check"></i><b>5.1.2</b> Ventajas e inconvenientes</a></li>
<li class="chapter" data-level="5.1.3" data-path="método-de-inversión.html"><a href="método-de-inversión.html#inversión-aproximada"><i class="fa fa-check"></i><b>5.1.3</b> Inversión aproximada</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="AR.html"><a href="AR.html"><i class="fa fa-check"></i><b>5.2</b> Método de aceptación rechazo</a><ul>
<li class="chapter" data-level="5.2.1" data-path="AR.html"><a href="AR.html#algoritmo"><i class="fa fa-check"></i><b>5.2.1</b> Algoritmo</a></li>
<li class="chapter" data-level="5.2.2" data-path="AR.html"><a href="AR.html#densidades-acotadas-en-un-intervalo-cerrado"><i class="fa fa-check"></i><b>5.2.2</b> Densidades acotadas en un intervalo cerrado</a></li>
<li class="chapter" data-level="5.2.3" data-path="AR.html"><a href="AR.html#eficiencia-del-algoritmo"><i class="fa fa-check"></i><b>5.2.3</b> Eficiencia del algoritmo</a></li>
<li class="chapter" data-level="5.2.4" data-path="AR.html"><a href="AR.html#ejemplo-inferencia-bayesiana"><i class="fa fa-check"></i><b>5.2.4</b> Ejemplo: Inferencia Bayesiana</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="modificaciones-del-método-de-aceptación-rechazo.html"><a href="modificaciones-del-método-de-aceptación-rechazo.html"><i class="fa fa-check"></i><b>5.3</b> Modificaciones del método de aceptación rechazo</a><ul>
<li class="chapter" data-level="5.3.1" data-path="modificaciones-del-método-de-aceptación-rechazo.html"><a href="modificaciones-del-método-de-aceptación-rechazo.html#muestreo-por-rechazo-adaptativo-ars"><i class="fa fa-check"></i><b>5.3.1</b> Muestreo por rechazo adaptativo (ARS)</a></li>
<li class="chapter" data-level="5.3.2" data-path="modificaciones-del-método-de-aceptación-rechazo.html"><a href="modificaciones-del-método-de-aceptación-rechazo.html#método-del-cociente-de-uniformes"><i class="fa fa-check"></i><b>5.3.2</b> Método del cociente de uniformes</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="método-de-composición.html"><a href="método-de-composición.html"><i class="fa fa-check"></i><b>5.4</b> Método de composición</a></li>
<li class="chapter" data-level="5.5" data-path="métodos-específicos-para-la-generación-de-algunas-distribuciones-notables.html"><a href="métodos-específicos-para-la-generación-de-algunas-distribuciones-notables.html"><i class="fa fa-check"></i><b>5.5</b> Métodos específicos para la generación de algunas distribuciones notables</a><ul>
<li class="chapter" data-level="5.5.1" data-path="métodos-específicos-para-la-generación-de-algunas-distribuciones-notables.html"><a href="métodos-específicos-para-la-generación-de-algunas-distribuciones-notables.html#método-de-box-müller"><i class="fa fa-check"></i><b>5.5.1</b> Método de Box-Müller</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="cap6.html"><a href="cap6.html"><i class="fa fa-check"></i><b>6</b> Simulación de variables discretas</a><ul>
<li class="chapter" data-level="6.1" data-path="método-de-la-transformación-cuantil.html"><a href="método-de-la-transformación-cuantil.html"><i class="fa fa-check"></i><b>6.1</b> Método de la transformación cuantil</a><ul>
<li class="chapter" data-level="6.1.1" data-path="método-de-la-transformación-cuantil.html"><a href="método-de-la-transformación-cuantil.html#eficiencia-del-algoritmo-1"><i class="fa fa-check"></i><b>6.1.1</b> Eficiencia del algoritmo</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="método-de-la-tabla-guía.html"><a href="método-de-la-tabla-guía.html"><i class="fa fa-check"></i><b>6.2</b> Método de la tabla guía</a></li>
<li class="chapter" data-level="6.3" data-path="alias.html"><a href="alias.html"><i class="fa fa-check"></i><b>6.3</b> Método de Alias</a></li>
<li class="chapter" data-level="6.4" data-path="simulación-de-una-variable-discreta-con-dominio-infinito.html"><a href="simulación-de-una-variable-discreta-con-dominio-infinito.html"><i class="fa fa-check"></i><b>6.4</b> Simulación de una variable discreta con dominio infinito</a></li>
<li class="chapter" data-level="6.5" data-path="cálculo-directo-de-la-función-cuantil.html"><a href="cálculo-directo-de-la-función-cuantil.html"><i class="fa fa-check"></i><b>6.5</b> Cálculo directo de la función cuantil</a></li>
<li class="chapter" data-level="6.6" data-path="otros-métodos.html"><a href="otros-métodos.html"><i class="fa fa-check"></i><b>6.6</b> Otros métodos</a></li>
<li class="chapter" data-level="6.7" data-path="métodos-específicos-para-generación-de-distribuciones-notables.html"><a href="métodos-específicos-para-generación-de-distribuciones-notables.html"><i class="fa fa-check"></i><b>6.7</b> Métodos específicos para generación de distribuciones notables</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="simulación-de-distribuciones-multivariantes.html"><a href="simulación-de-distribuciones-multivariantes.html"><i class="fa fa-check"></i><b>7</b> Simulación de distribuciones multivariantes</a><ul>
<li class="chapter" data-level="7.1" data-path="simulación-de-componentes-independientes.html"><a href="simulación-de-componentes-independientes.html"><i class="fa fa-check"></i><b>7.1</b> Simulación de componentes independientes</a></li>
<li class="chapter" data-level="7.2" data-path="el-método-de-aceptaciónrechazo.html"><a href="el-método-de-aceptaciónrechazo.html"><i class="fa fa-check"></i><b>7.2</b> El método de aceptación/rechazo</a></li>
<li class="chapter" data-level="7.3" data-path="fact-cov.html"><a href="fact-cov.html"><i class="fa fa-check"></i><b>7.3</b> Factorización de la matriz de covarianzas</a></li>
<li class="chapter" data-level="7.4" data-path="distrcond.html"><a href="distrcond.html"><i class="fa fa-check"></i><b>7.4</b> Método de las distribuciones condicionadas</a></li>
<li class="chapter" data-level="7.5" data-path="simulación-condicional-e-incondicional.html"><a href="simulación-condicional-e-incondicional.html"><i class="fa fa-check"></i><b>7.5</b> Simulación condicional e incondicional</a><ul>
<li class="chapter" data-level="7.5.1" data-path="simulación-condicional-e-incondicional.html"><a href="simulación-condicional-e-incondicional.html#condnormal"><i class="fa fa-check"></i><b>7.5.1</b> Simulación condicional de una normal multivariante</a></li>
<li class="chapter" data-level="7.5.2" data-path="simulación-condicional-e-incondicional.html"><a href="simulación-condicional-e-incondicional.html#simulación-condicional-a-partir-de-un-modelo-ajustado"><i class="fa fa-check"></i><b>7.5.2</b> Simulación condicional a partir de un modelo ajustado</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="simulación-basada-en-cópulas.html"><a href="simulación-basada-en-cópulas.html"><i class="fa fa-check"></i><b>7.6</b> Simulación basada en cópulas</a><ul>
<li class="chapter" data-level="7.6.1" data-path="simulación-basada-en-cópulas.html"><a href="simulación-basada-en-cópulas.html#cópulas-arquimedianas"><i class="fa fa-check"></i><b>7.6.1</b> Cópulas Arquimedianas</a></li>
<li class="chapter" data-level="7.6.2" data-path="simulación-basada-en-cópulas.html"><a href="simulación-basada-en-cópulas.html#simulación"><i class="fa fa-check"></i><b>7.6.2</b> Simulación</a></li>
</ul></li>
<li class="chapter" data-level="7.7" data-path="mult-discr.html"><a href="mult-discr.html"><i class="fa fa-check"></i><b>7.7</b> Simulación de distribuciones multivariantes discretas</a><ul>
<li class="chapter" data-level="7.7.1" data-path="mult-discr.html"><a href="mult-discr.html#métodos-de-codificación-o-etiquetado-para-variables-discretas"><i class="fa fa-check"></i><b>7.7.1</b> Métodos de codificación o etiquetado para variables discretas</a></li>
<li class="chapter" data-level="7.7.2" data-path="mult-discr.html"><a href="mult-discr.html#simulación-de-una-variable-discreta-bidimensional"><i class="fa fa-check"></i><b>7.7.2</b> Simulación de una variable discreta bidimensional</a></li>
<li class="chapter" data-level="7.7.3" data-path="mult-discr.html"><a href="mult-discr.html#simconting"><i class="fa fa-check"></i><b>7.7.3</b> Simulación de tablas de contingencia</a></li>
</ul></li>
<li class="chapter" data-level="7.8" data-path="ejercicios-propuestos.html"><a href="ejercicios-propuestos.html"><i class="fa fa-check"></i><b>7.8</b> Ejercicios propuestos</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="cap8.html"><a href="cap8.html"><i class="fa fa-check"></i><b>8</b> Aplicaciones de la simulación en Inferencia Estadística</a><ul>
<li class="chapter" data-level="8.1" data-path="distribución-en-el-muestreo.html"><a href="distribución-en-el-muestreo.html"><i class="fa fa-check"></i><b>8.1</b> Distribución en el muestreo</a></li>
<li class="chapter" data-level="8.2" data-path="intervalos-de-confianza.html"><a href="intervalos-de-confianza.html"><i class="fa fa-check"></i><b>8.2</b> Intervalos de confianza</a></li>
<li class="chapter" data-level="8.3" data-path="contrastes.html"><a href="contrastes.html"><i class="fa fa-check"></i><b>8.3</b> Contrastes de hipótesis</a></li>
<li class="chapter" data-level="8.4" data-path="comparación-de-estimadores.html"><a href="comparación-de-estimadores.html"><i class="fa fa-check"></i><b>8.4</b> Comparación de estimadores</a></li>
<li class="chapter" data-level="8.5" data-path="remuestreo-bootstrap.html"><a href="remuestreo-bootstrap.html"><i class="fa fa-check"></i><b>8.5</b> Remuestreo Bootstrap</a><ul>
<li class="chapter" data-level="8.5.1" data-path="remuestreo-bootstrap.html"><a href="remuestreo-bootstrap.html#idea"><i class="fa fa-check"></i><b>8.5.1</b> Idea:</a></li>
<li class="chapter" data-level="8.5.2" data-path="remuestreo-bootstrap.html"><a href="remuestreo-bootstrap.html#métodos-de-remuestreo-bootstrap"><i class="fa fa-check"></i><b>8.5.2</b> Métodos de remuestreo Bootstrap</a></li>
<li class="chapter" data-level="8.5.3" data-path="remuestreo-bootstrap.html"><a href="remuestreo-bootstrap.html#ejemplo"><i class="fa fa-check"></i><b>8.5.3</b> Ejemplo</a></li>
<li class="chapter" data-level="8.5.4" data-path="remuestreo-bootstrap.html"><a href="remuestreo-bootstrap.html#paquetes-r-bootstrap-boot"><i class="fa fa-check"></i><b>8.5.4</b> Paquetes R: bootstrap, boot</a></li>
<li class="chapter" data-level="8.5.5" data-path="remuestreo-bootstrap.html"><a href="remuestreo-bootstrap.html#gráficos"><i class="fa fa-check"></i><b>8.5.5</b> Gráficos</a></li>
<li class="chapter" data-level="8.5.6" data-path="remuestreo-bootstrap.html"><a href="remuestreo-bootstrap.html#intervalos-de-confianza-bootstrap"><i class="fa fa-check"></i><b>8.5.6</b> Intervalos de confianza bootstrap</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="cap9.html"><a href="cap9.html"><i class="fa fa-check"></i><b>9</b> Integración y Optimización Montecarlo</a><ul>
<li class="chapter" data-level="9.1" data-path="integración-monte-carlo-clásica.html"><a href="integración-monte-carlo-clásica.html"><i class="fa fa-check"></i><b>9.1</b> Integración Monte Carlo (clásica)</a><ul>
<li class="chapter" data-level="9.1.1" data-path="integración-monte-carlo-clásica.html"><a href="integración-monte-carlo-clásica.html#caso-general"><i class="fa fa-check"></i><b>9.1.1</b> Caso general</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="muestreo-por-importancia.html"><a href="muestreo-por-importancia.html"><i class="fa fa-check"></i><b>9.2</b> Muestreo por importancia</a><ul>
<li class="chapter" data-level="9.2.1" data-path="muestreo-por-importancia.html"><a href="muestreo-por-importancia.html#remuestreo-del-muestreo-por-importancia"><i class="fa fa-check"></i><b>9.2.1</b> Remuestreo (del muestreo) por importancia</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="optimización-monte-carlo.html"><a href="optimización-monte-carlo.html"><i class="fa fa-check"></i><b>9.3</b> Optimización Monte Carlo</a><ul>
<li class="chapter" data-level="9.3.1" data-path="optimización-monte-carlo.html"><a href="optimización-monte-carlo.html#algoritmos-de-optimización-monte-carlo"><i class="fa fa-check"></i><b>9.3.1</b> Algoritmos de optimización Monte Carlo</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="temple-simulado.html"><a href="temple-simulado.html"><i class="fa fa-check"></i><b>9.4</b> Temple simulado</a><ul>
<li class="chapter" data-level="9.4.1" data-path="temple-simulado.html"><a href="temple-simulado.html#algoritmo-1"><i class="fa fa-check"></i><b>9.4.1</b> Algoritmo:</a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="algoritmos-genéticos.html"><a href="algoritmos-genéticos.html"><i class="fa fa-check"></i><b>9.5</b> Algoritmos genéticos</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="técnicas-de-reducción-de-la-varianza.html"><a href="técnicas-de-reducción-de-la-varianza.html"><i class="fa fa-check"></i><b>10</b> Técnicas de reducción de la varianza</a><ul>
<li class="chapter" data-level="10.1" data-path="reducción-de-la-varianza.html"><a href="reducción-de-la-varianza.html"><i class="fa fa-check"></i><b>10.1</b> Reducción de la varianza</a></li>
<li class="chapter" data-level="10.2" data-path="variables-antitéticas.html"><a href="variables-antitéticas.html"><i class="fa fa-check"></i><b>10.2</b> Variables antitéticas</a><ul>
<li class="chapter" data-level="10.2.1" data-path="variables-antitéticas.html"><a href="variables-antitéticas.html#ejemplo-integración-monte-carlo"><i class="fa fa-check"></i><b>10.2.1</b> Ejemplo: Integración Monte Carlo</a></li>
<li class="chapter" data-level="10.2.2" data-path="variables-antitéticas.html"><a href="variables-antitéticas.html#generación-de-variables-antitéticas"><i class="fa fa-check"></i><b>10.2.2</b> Generación de variables antitéticas</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="estratificación.html"><a href="estratificación.html"><i class="fa fa-check"></i><b>10.3</b> Estratificación</a></li>
<li class="chapter" data-level="10.4" data-path="variables-de-control.html"><a href="variables-de-control.html"><i class="fa fa-check"></i><b>10.4</b> Variables de control</a></li>
<li class="chapter" data-level="10.5" data-path="números-aleatorios-comunes.html"><a href="números-aleatorios-comunes.html"><i class="fa fa-check"></i><b>10.5</b> Números aleatorios comunes</a></li>
<li class="chapter" data-level="10.6" data-path="ejercicios-fin-de-práctica.html"><a href="ejercicios-fin-de-práctica.html"><i class="fa fa-check"></i><b>10.6</b> Ejercicios fin de práctica</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="referencias.html"><a href="referencias.html"><i class="fa fa-check"></i>Referencias</a><ul>
<li class="chapter" data-level="" data-path="bibliografía-básica.html"><a href="bibliografía-básica.html"><i class="fa fa-check"></i>Bibliografía básica</a></li>
<li class="chapter" data-level="" data-path="bibliografía-complementaria.html"><a href="bibliografía-complementaria.html"><i class="fa fa-check"></i>Bibliografía complementaria</a><ul>
<li class="chapter" data-level="" data-path="bibliografía-complementaria.html"><a href="bibliografía-complementaria.html#libros"><i class="fa fa-check"></i>Libros</a></li>
<li class="chapter" data-level="" data-path="bibliografía-complementaria.html"><a href="bibliografía-complementaria.html#artículos"><i class="fa fa-check"></i>Artículos</a></li>
</ul></li>
</ul></li>
<li class="appendix"><span><b>Apendices</b></span></li>
<li class="chapter" data-level="A" data-path="links.html"><a href="links.html"><i class="fa fa-check"></i><b>A</b> Enlaces</a></li>
<li class="chapter" data-level="B" data-path="gof-aleat.html"><a href="gof-aleat.html"><i class="fa fa-check"></i><b>B</b> Bondad de Ajuste y Aleatoriedad</a><ul>
<li class="chapter" data-level="B.1" data-path="gof.html"><a href="gof.html"><i class="fa fa-check"></i><b>B.1</b> Métodos de bondad de ajuste</a><ul>
<li class="chapter" data-level="B.1.1" data-path="gof.html"><a href="gof.html#histograma"><i class="fa fa-check"></i><b>B.1.1</b> Histograma</a></li>
<li class="chapter" data-level="B.1.2" data-path="gof.html"><a href="gof.html#empdistr"><i class="fa fa-check"></i><b>B.1.2</b> Función de distribución empírica</a></li>
<li class="chapter" data-level="B.1.3" data-path="gof.html"><a href="gof.html#gráficos-p-p-y-q-q"><i class="fa fa-check"></i><b>B.1.3</b> Gráficos P-P y Q-Q</a></li>
<li class="chapter" data-level="B.1.4" data-path="gof.html"><a href="gof.html#chi2test"><i class="fa fa-check"></i><b>B.1.4</b> Contraste ji-cuadrado de Pearson</a></li>
<li class="chapter" data-level="B.1.5" data-path="gof.html"><a href="gof.html#contraste-de-kolmogorov-smirnov"><i class="fa fa-check"></i><b>B.1.5</b> Contraste de Kolmogorov-Smirnov</a></li>
</ul></li>
<li class="chapter" data-level="B.2" data-path="diagnosis-de-la-independencia.html"><a href="diagnosis-de-la-independencia.html"><i class="fa fa-check"></i><b>B.2</b> Diagnosis de la independencia</a><ul>
<li class="chapter" data-level="B.2.1" data-path="diagnosis-de-la-independencia.html"><a href="diagnosis-de-la-independencia.html#métodos-para-detectar-dependencia"><i class="fa fa-check"></i><b>B.2.1</b> Métodos para detectar dependencia</a></li>
<li class="chapter" data-level="B.2.2" data-path="diagnosis-de-la-independencia.html"><a href="diagnosis-de-la-independencia.html#gráfico-secuencial"><i class="fa fa-check"></i><b>B.2.2</b> Gráfico secuencial</a></li>
<li class="chapter" data-level="B.2.3" data-path="diagnosis-de-la-independencia.html"><a href="diagnosis-de-la-independencia.html#gráfico-de-dispersion-retardado"><i class="fa fa-check"></i><b>B.2.3</b> Gráfico de dispersion retardado</a></li>
<li class="chapter" data-level="B.2.4" data-path="diagnosis-de-la-independencia.html"><a href="diagnosis-de-la-independencia.html#el-correlograma"><i class="fa fa-check"></i><b>B.2.4</b> El correlograma</a></li>
<li class="chapter" data-level="B.2.5" data-path="diagnosis-de-la-independencia.html"><a href="diagnosis-de-la-independencia.html#test-de-rachas"><i class="fa fa-check"></i><b>B.2.5</b> Test de rachas</a></li>
<li class="chapter" data-level="B.2.6" data-path="diagnosis-de-la-independencia.html"><a href="diagnosis-de-la-independencia.html#el-contraste-de-ljung-box"><i class="fa fa-check"></i><b>B.2.6</b> El contraste de Ljung-Box</a></li>
</ul></li>
<li class="chapter" data-level="B.3" data-path="contrastes-específicos-para-generadores-aleatorios.html"><a href="contrastes-específicos-para-generadores-aleatorios.html"><i class="fa fa-check"></i><b>B.3</b> Contrastes específicos para generadores aleatorios</a><ul>
<li class="chapter" data-level="B.3.1" data-path="contrastes-específicos-para-generadores-aleatorios.html"><a href="contrastes-específicos-para-generadores-aleatorios.html#contraste-de-frecuencias"><i class="fa fa-check"></i><b>B.3.1</b> Contraste de frecuencias</a></li>
<li class="chapter" data-level="B.3.2" data-path="contrastes-específicos-para-generadores-aleatorios.html"><a href="contrastes-específicos-para-generadores-aleatorios.html#contraste-de-series"><i class="fa fa-check"></i><b>B.3.2</b> Contraste de series</a></li>
<li class="chapter" data-level="B.3.3" data-path="contrastes-específicos-para-generadores-aleatorios.html"><a href="contrastes-específicos-para-generadores-aleatorios.html#el-contraste-del-poker"><i class="fa fa-check"></i><b>B.3.3</b> El contraste del poker</a></li>
<li class="chapter" data-level="B.3.4" data-path="contrastes-específicos-para-generadores-aleatorios.html"><a href="contrastes-específicos-para-generadores-aleatorios.html#el-contraste-del-coleccionista"><i class="fa fa-check"></i><b>B.3.4</b> El contraste del coleccionista</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="C" data-path="int-num.html"><a href="int-num.html"><i class="fa fa-check"></i><b>C</b> Integración numérica</a><ul>
<li class="chapter" data-level="C.1" data-path="integración-numérica-unidimensional.html"><a href="integración-numérica-unidimensional.html"><i class="fa fa-check"></i><b>C.1</b> Integración numérica unidimensional</a><ul>
<li class="chapter" data-level="C.1.1" data-path="integración-numérica-unidimensional.html"><a href="integración-numérica-unidimensional.html#método-del-trapezoide"><i class="fa fa-check"></i><b>C.1.1</b> Método del trapezoide</a></li>
<li class="chapter" data-level="C.1.2" data-path="integración-numérica-unidimensional.html"><a href="integración-numérica-unidimensional.html#regla-de-simpson"><i class="fa fa-check"></i><b>C.1.2</b> Regla de Simpson</a></li>
<li class="chapter" data-level="C.1.3" data-path="integración-numérica-unidimensional.html"><a href="integración-numérica-unidimensional.html#cuadratura-adaptativa"><i class="fa fa-check"></i><b>C.1.3</b> Cuadratura adaptativa</a></li>
<li class="chapter" data-level="C.1.4" data-path="integración-numérica-unidimensional.html"><a href="integración-numérica-unidimensional.html#comandos-de-r"><i class="fa fa-check"></i><b>C.1.4</b> Comandos de <code>R</code></a></li>
</ul></li>
<li class="chapter" data-level="C.2" data-path="integración-numérica-bidimensional.html"><a href="integración-numérica-bidimensional.html"><i class="fa fa-check"></i><b>C.2</b> Integración numérica bidimensional</a><ul>
<li class="chapter" data-level="C.2.1" data-path="integración-numérica-bidimensional.html"><a href="integración-numérica-bidimensional.html#representación-gráfica"><i class="fa fa-check"></i><b>C.2.1</b> Representación gráfica</a></li>
<li class="chapter" data-level="C.2.2" data-path="integración-numérica-bidimensional.html"><a href="integración-numérica-bidimensional.html#método-del-trapezoide-1"><i class="fa fa-check"></i><b>C.2.2</b> Método del trapezoide</a></li>
<li class="chapter" data-level="C.2.3" data-path="integración-numérica-bidimensional.html"><a href="integración-numérica-bidimensional.html#comandos-de-r-1"><i class="fa fa-check"></i><b>C.2.3</b> Comandos de <code>R</code></a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Simulación Estadística</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="diagnosis-de-la-independencia" class="section level2">
<h2><span class="header-section-number">B.2</span> Diagnosis de la independencia</h2>
<p>Los métodos “clásicos” de inferencia estadística se basan en suponer que las observaciones <span class="math inline">\(X_{1},\ldots,X_{n}\)</span> son una muestra aleatoria simple (m.a.s.) de <span class="math inline">\(X\)</span>. Por tanto suponen que las observaciones son independientes (o los errores, en el caso de un modelo de regresión).</p>
<ul>
<li><p>La ausencia de aleatoriedad es difícil de corregir y puede influir notablemente en el análisis estadístico.</p></li>
<li><p>Si existe dependencia entre las observaciones muestrales (e.g. el conocimiento de <span class="math inline">\(X_{i}\)</span> proporciona información sobre los valores de <span class="math inline">\(X_{i+1}\)</span>, <span class="math inline">\(X_{i+2}\)</span>, <span class="math inline">\(\ldots\)</span>), los métodos “clásicos” no serán en principio adecuados (pueden conducir a conclusiones erróneas).</p>
<ul>
<li><p>Esto es debido principalmente a que introduce un sesgo en los estimadores de las varianzas (diseñados asumiendo independencia).</p></li>
<li><p>Los correspondientes intervalos de confianza y contrastes de hipótesis tendrán una confianza o una potencia distinta de la que deberían (aunque las estimaciones de los parámetros pueden no verse muy afectadas).</p></li>
</ul></li>
</ul>
<p>Si <span class="math inline">\(X_{1}\)</span> e <span class="math inline">\(X_{2}\)</span> son independientes (<span class="math inline">\(Cov(X_{1},X_{2})=0\)</span>): <span class="math display">\[Var(X_{1}+X_{2})=Var(X_{1})+Var(X_{2})\]</span></p>
<p>En el caso general (dependencia): <span class="math display">\[Var(X_{1}+X_{2})=Var(X_{1})+Var(X_{2})+2Cov(X_{1},X_{2})\]</span></p>
<p>Típicamente <span class="math inline">\(Cov(X_{1},X_{2})&gt;0\)</span> por lo que con los métodos “clásicos” (basados en independencia) se suelen producir subestimaciones de las varianzas (IC más estrechos y tendencia a rechazar <span class="math inline">\(H_{0}\)</span> en contrastes).</p>
<p><strong>Ejemplo</strong>: datos simulados</p>
<p>Consideramos un proceso temporal estacionario con dependencia exponencial (la dependencia entre las observaciones depende del “salto” entre ellas; ver Ejemplo <a href="fact-cov.html#exm:funcional">7.3</a> en la Sección <a href="fact-cov.html#fact-cov">7.3</a>).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">n &lt;-<span class="st"> </span><span class="dv">100</span>          <span class="co"># Nº de observaciones</span>
t &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dt">length =</span> n)
mu &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="dv">0</span>, n)   <span class="co"># Media</span>
<span class="co"># mu &lt;- 0.25 + 0.5*t</span>
<span class="co"># mu &lt;- sin(2*pi*t)</span>

<span class="co"># Matriz de covarianzas</span>
t.dist &lt;-<span class="st"> </span><span class="kw">as.matrix</span>(<span class="kw">dist</span>(t))
t.cov &lt;-<span class="st"> </span><span class="kw">exp</span>(<span class="op">-</span>t.dist)
<span class="co"># str(t.cov)</span>
<span class="co"># num [1:100, 1:100] 1 0.99 0.98 0.97 0.96 ...</span>

<span class="co"># Simulación de las observaciones</span>
<span class="kw">set.seed</span>(<span class="dv">1</span>)
<span class="kw">library</span>(MASS)

z &lt;-<span class="st"> </span><span class="kw">rnorm</span>(n)
x1 &lt;-<span class="st"> </span>mu <span class="op">+</span><span class="st"> </span>z <span class="co"># Datos independientes</span>
x2 &lt;-<span class="st"> </span><span class="kw">mvrnorm</span>(<span class="dv">1</span>, mu, t.cov) <span class="co"># Datos dependientes</span>

<span class="kw">plot</span>(t, mu, <span class="dt">type=</span><span class="st">&quot;l&quot;</span>, <span class="dt">lwd =</span> <span class="dv">2</span>, <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="op">-</span><span class="dv">3</span>,<span class="dv">3</span>), <span class="dt">ylab =</span> <span class="st">&#39;x&#39;</span>)
<span class="kw">lines</span>(t, x1, <span class="dt">col =</span> <span class="st">&#39;blue&#39;</span>)
<span class="kw">lines</span>(t, x2, <span class="dt">col =</span> <span class="st">&#39;red&#39;</span>)
<span class="kw">legend</span>(<span class="st">&quot;bottomright&quot;</span>, <span class="dt">legend =</span> <span class="kw">c</span>(<span class="st">&quot;Datos independientes&quot;</span>, <span class="st">&quot;Datos dependientes&quot;</span>), <span class="dt">col =</span> <span class="kw">c</span>(<span class="st">&#39;blue&#39;</span>, <span class="st">&#39;red&#39;</span>), <span class="dt">lty =</span> <span class="dv">1</span>)</code></pre></div>
<p><img src="22-Bondad_ajuste_Aleatoriedad_files/figure-html/unnamed-chunk-11-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>En el caso anterior la varianza es uno con ambos procesos. Las estimaciones suponiendo independencia serían:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">var</span>(x1)</code></pre></div>
<pre><code>## [1] 0.8067621</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">var</span>(x2)</code></pre></div>
<pre><code>## [1] 0.1108155</code></pre>
<p>En el caso de datos dependientes se produce una clara subestimación de la varianza</p>
<div id="métodos-para-detectar-dependencia" class="section level3">
<h3><span class="header-section-number">B.2.1</span> Métodos para detectar dependencia</h3>
<p>Es de esperar que datos cercanos en el tiempo (o en el espacio) sean más parecidos (dependientes) que datos más alejados, hablaríamos entonces de dependencia temporal (espacial o espacio-temporal).</p>
<p>En esta sección nos centraremos en el caso de dependencia temporal (unidimensional). Entre los métodos para detectar este tipo de dependencia destacaríamos:</p>
<ul>
<li><p>Gráficos:</p>
<ul>
<li><p>Secuencial / Dispersión frente al tiempo</p></li>
<li><p>Dispersión retardado</p></li>
<li><p>Correlograma</p></li>
</ul></li>
<li><p>Contrastes:</p>
<ul>
<li><p>Tests basados en rachas</p></li>
<li><p>Test de Ljung-Box</p></li>
</ul></li>
</ul>
</div>
<div id="gráfico-secuencial" class="section level3">
<h3><span class="header-section-number">B.2.2</span> Gráfico secuencial</h3>
<p>El gráfico de dispersión <span class="math inline">\(\{(i,X_{i}) : i = 1, \ldots, n \}\)</span> permite detectar la presencia de un efecto temporal (en la tendencia o en la variabilidad).</p>
<ul>
<li><p>Es importante mantener/guardar el orden de recogida de los datos.</p></li>
<li><p>Si existe una tendencia los datos no son homogéneos (debería tenerse en cuenta la variable índice, o tiempo, como variable explicativa). Podría indicar la presencia de un “efecto aprendizaje”.</p></li>
<li><p>Comandos R: <code>plot(as.ts(x))</code></p></li>
</ul>
<p>Ejemplo:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">old.par &lt;-<span class="st"> </span><span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))
<span class="kw">plot</span>(datos, <span class="dt">type =</span> <span class="st">&#39;l&#39;</span>)
<span class="kw">plot</span>(<span class="kw">as.ts</span>(datos))</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:grafsec"></span>
<img src="22-Bondad_ajuste_Aleatoriedad_files/figure-html/grafsec-1.png" alt="Ejemplos de gráficos secuenciales." width="70%" />
<p class="caption">
Figura B.3: Ejemplos de gráficos secuenciales.
</p>
</div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">par</span>(old.par)</code></pre></div>
<p>Es habitual que este tipo de análisis se realice sobre los residuos de un modelo de regresión (e.g. <code>datos &lt;- residuals(modelo)</code>)</p>
<p>Este gráfico también podría servir para detectar dependencia temporal:</p>
<ul>
<li><p>Valores próximos muy parecidos (valores grandes seguidos de grandes y viceversa) indicarían una posible dependencia positiva.</p></li>
<li><p>Valores próximos dispares (valores grandes seguidos de pequeños y viceversa) indicarían una posible dependencia negativa.</p></li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">old.par &lt;-<span class="st"> </span><span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">3</span>))
<span class="kw">plot</span>(x2, <span class="dt">type =</span> <span class="st">&#39;l&#39;</span>, <span class="dt">ylab =</span> <span class="st">&#39;&#39;</span>, <span class="dt">main =</span> <span class="st">&#39;Dependencia positiva&#39;</span>)
<span class="kw">plot</span>(x1, <span class="dt">type =</span> <span class="st">&#39;l&#39;</span>, <span class="dt">ylab =</span> <span class="st">&#39;&#39;</span>, <span class="dt">main =</span> <span class="st">&#39;Independencia&#39;</span>)
x3 &lt;-<span class="st"> </span>x2 <span class="op">*</span><span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span>, <span class="op">-</span><span class="dv">1</span>)
<span class="kw">plot</span>(x3, <span class="dt">type =</span> <span class="st">&#39;l&#39;</span>, <span class="dt">ylab =</span> <span class="st">&#39;&#39;</span>, <span class="dt">main =</span> <span class="st">&#39;Dependencia negativa&#39;</span>)</code></pre></div>
<p><img src="22-Bondad_ajuste_Aleatoriedad_files/figure-html/unnamed-chunk-13-1.png" width="70%" style="display: block; margin: auto;" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">par</span>(old.par)</code></pre></div>
<p>pero suele ser preferible emplear un gráfico de dispersión retardado.</p>
</div>
<div id="gráfico-de-dispersion-retardado" class="section level3">
<h3><span class="header-section-number">B.2.3</span> Gráfico de dispersion retardado</h3>
<p>El gráfico de dispersión <span class="math inline">\(\{(X_{i},X_{i+1}) : i = 1, \ldots, n-1 \}\)</span> permite detectar dependencias a un retardo (relaciones entre valores separados por un instante)</p>
<ul>
<li>Comando R:<code>plot(x[-length(x)], x[-1], xlab = &quot;X_t&quot;, ylab = &quot;X_t+1&quot;)</code></li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">old.par &lt;-<span class="st"> </span><span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">3</span>))
<span class="kw">plot</span>(x2[<span class="op">-</span><span class="kw">length</span>(x2)], x2[<span class="op">-</span><span class="dv">1</span>], <span class="dt">xlab =</span> <span class="st">&quot;X_t&quot;</span>, <span class="dt">ylab =</span> <span class="st">&quot;X_t+1&quot;</span>, <span class="dt">main =</span> <span class="st">&#39;Dependencia positiva&#39;</span>)
<span class="kw">plot</span>(x1[<span class="op">-</span><span class="kw">length</span>(x1)], x1[<span class="op">-</span><span class="dv">1</span>], <span class="dt">xlab =</span> <span class="st">&quot;X_t&quot;</span>, <span class="dt">ylab =</span> <span class="st">&quot;X_t+1&quot;</span>, <span class="dt">main =</span> <span class="st">&#39;Independencia&#39;</span>)
<span class="kw">plot</span>(x3[<span class="op">-</span><span class="kw">length</span>(x3)], x3[<span class="op">-</span><span class="dv">1</span>], <span class="dt">xlab =</span> <span class="st">&quot;X_t&quot;</span>, <span class="dt">ylab =</span> <span class="st">&quot;X_t+1&quot;</span>, <span class="dt">main =</span> <span class="st">&#39;Dependencia negativa&#39;</span>)</code></pre></div>
<p><img src="22-Bondad_ajuste_Aleatoriedad_files/figure-html/unnamed-chunk-14-1.png" width="70%" style="display: block; margin: auto;" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">par</span>(old.par)</code></pre></div>
<p>Se puede generalizar al gráfico <span class="math inline">\(\{(X_{i},X_{i+k}) : i = 1, \ldots, n-k \}\)</span> que permite detectar dependencias a <span class="math inline">\(k\)</span> retardos (separadas <span class="math inline">\(k\)</span> instantes).</p>
<p><strong>Ejemplo</strong></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Gráfico de dispersion retardado</span>
<span class="kw">plot</span>(datos[<span class="op">-</span><span class="kw">length</span>(datos)], datos[<span class="op">-</span><span class="dv">1</span>], <span class="dt">xlab =</span> <span class="st">&quot;X_t&quot;</span>, <span class="dt">ylab =</span> <span class="st">&quot;X_t+1&quot;</span>)</code></pre></div>
<p><img src="22-Bondad_ajuste_Aleatoriedad_files/figure-html/unnamed-chunk-15-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>El correspondiente coeficiente de correlación es una medida numérica del grado de relación lineal (denominado autocorrelación de orden 1).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">cor</span>(datos[<span class="op">-</span><span class="kw">length</span>(datos)], datos[<span class="op">-</span><span class="dv">1</span>])</code></pre></div>
<pre><code>## [1] 0.01344127</code></pre>
<p><strong>Ejemplo</strong>: Calidad de un generador aleatorio</p>
<p>En el caso de una secuencia muy grande de número pseudoaleatorios (supuestamente independientes), sería muy dificil distinguir un patrón a partir del gráfico anterior. La recomendación en R sería utilizar puntos con color de relleno:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(u[<span class="op">-</span><span class="kw">length</span>(u)], u[<span class="op">-</span><span class="dv">1</span>], <span class="dt">xlab=</span><span class="st">&quot;U_t&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;U_t+1&quot;</span>, <span class="dt">pch=</span><span class="dv">21</span>, <span class="dt">bg=</span><span class="st">&quot;white&quot;</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:dispret"></span>
<img src="22-Bondad_ajuste_Aleatoriedad_files/figure-html/dispret-1.png" alt="Ejemplos de gráficos de dispensión retardados de dos secuencias de longitud 10000." width="70%" />
<p class="caption">
Figura B.4: Ejemplos de gráficos de dispensión retardados de dos secuencias de longitud 10000.
</p>
</div>
<p>Si se observa algún tipo de patrón indicaría dependencia (se podría considerar como una versión descriptiva del denominado “Parking lot test”). Se puede generalizar también a <span class="math inline">\(d\)</span>-uplas <span class="math inline">\((X_{t+1},X_{t+2},\ldots,X_{t+d})\)</span> (ver ejemplo del generador RANDU en Figura <a href="gen-cong.html#fig:randu">3.1</a> de la Sección <a href="gen-cong.html#gen-cong">3.1</a>).</p>
</div>
<div id="el-correlograma" class="section level3">
<h3><span class="header-section-number">B.2.4</span> El correlograma</h3>
<p>Para estudiar si el grado de relación (lineal) entre <span class="math inline">\(X_{i}\)</span> e <span class="math inline">\(X_{i+k}\)</span> podemos utilizar el coeficiente de correlación:</p>
<p><span class="math display">\[\rho\left(  X_{i},X_{i+k}\right) = \frac{Cov\left(  X_{i},X_{i+k}\right)    }
{\sigma\left(  X_{i}\right)  \sigma\left(  X_{i+k}\right)  }\]</span></p>
<ul>
<li><p>En el caso de datos homogéneos (estacionarios) la correlación sería función únicamente del salto: <span class="math display">\[\rho\left(  X_{i},X_{i+k}\right)  \equiv\rho\left(  k\right)\]</span> denominada función de autocorrelación simple (fas) o correlograma.</p></li>
<li><p>Su estimador es el correlograma muestral: <span class="math display">\[r(k)=\frac{\sum_{i=1}^{n-k}(X_{i}-\overline{X})(X_{i+k}-\overline{X})}
{\sum_{i=1}^{n}(X_{i}-\overline{X})^{2}}\]</span></p></li>
<li><p>Comando R:<code>acf(x)</code></p></li>
</ul>
<p>En caso de independencia es de esperar que las autocorrelaciones muestrales sean próximas a cero (valores “grandes” indicarían dependencia positiva o negativa según el signo).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">old.par &lt;-<span class="st"> </span><span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">3</span>))
<span class="kw">acf</span>(x1, <span class="dt">main =</span> <span class="st">&#39;Independencia&#39;</span>)
<span class="kw">acf</span>(x2, <span class="dt">main =</span> <span class="st">&#39;Dependencia positiva&#39;</span>)
<span class="kw">acf</span>(x3, <span class="dt">main =</span> <span class="st">&#39;Dependencia negativa&#39;</span>)</code></pre></div>
<p><img src="22-Bondad_ajuste_Aleatoriedad_files/figure-html/unnamed-chunk-18-1.png" width="70%" style="display: block; margin: auto;" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">par</span>(old.par)</code></pre></div>
<p>Suponiendo normalidad e independencia, asintóticamente: <span class="math display">\[r(k)\underset{aprox.}{\sim}N\left(  \rho(k),\frac{1}{n}\right)\]</span></p>
<ul>
<li><p>Si el tamaño muestral es grande, podríamos aceptar <span class="math inline">\(H_{0}:\)</span> <span class="math inline">\(\rho\left( k\right) = 0\)</span> si:<span class="math display">\[|r(k)|&lt;\dfrac{2}{\sqrt{n}}\]</span></p></li>
<li><p>En el <em>gráfico de autocorrelaciones muestrales</em> (también denominado correlograma) se representan las estimaciones <span class="math inline">\(r(k)\)</span> de las autocorrelaciones correspondientes a los primeros retardos (típicamente <span class="math inline">\(k&lt;n/4\)</span>) y las correspondientes bandas de confianza (para detectar dependencias significativas).</p></li>
</ul>
<p><strong>Ejemplo</strong></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">acf</span>(datos)  <span class="co"># correlaciones</span></code></pre></div>
<p><img src="22-Bondad_ajuste_Aleatoriedad_files/figure-html/unnamed-chunk-19-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>La función <code>acf</code> también permite estimar el covariograma<a href="#fn5" class="footnoteRef" id="fnref5"><sup>5</sup></a>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">covar &lt;-<span class="st"> </span><span class="kw">acf</span>(x2, <span class="dt">type =</span> <span class="st">&quot;covariance&quot;</span>)</code></pre></div>
<p><img src="22-Bondad_ajuste_Aleatoriedad_files/figure-html/unnamed-chunk-20-1.png" width="70%" style="display: block; margin: auto;" /></p>
</div>
<div id="test-de-rachas" class="section level3">
<h3><span class="header-section-number">B.2.5</span> Test de rachas</h3>
<p>Permite contrastar si el orden de aparición de dos valores de una variable dicotómica es aleatorio. Supongamos que <span class="math inline">\(X\)</span> toma los valores <span class="math inline">\(+\)</span> y <span class="math inline">\(-\)</span> y que observamos una muestra del tipo: <span class="math display">\[++++---+++--++++++----\]</span> y nos interesa contrastar:</p>
<p><span class="math display">\[\left\{ \begin{array}[c]{l}
    H_{0}:\mathit{La\ muestra\ es\ aleatoria}\\
    H_{1}:\mathit{La\ muestra\ no\ es\ aleatoria}
\end{array}
\right.\]</span></p>
<p>Una <em>racha</em> es una secuencia de observaciones iguales (o similares): <span class="math display">\[\underbrace{++++}_{1}\underbrace{---}_{2}\underbrace{+++}_{3}
\underbrace{--}_{4}\underbrace{++++++}_{5}\underbrace{----}_{6}\]</span></p>
<ul>
<li><p>Una muestra con “muchas” o “pocas” rachas sugeriría que la muestra no es aleatoria (con dependencia negativa o positiva, respec.).</p></li>
<li><p>Estadístico del contraste: <span class="math display">\[R=\text{&quot;Número total de rachas en la muestra&quot;}\]</span></p></li>
<li><p>Bajo la hipótesis nula de aleatoriedad: <span class="math display">\[R\underset{aprox.}{\sim}N\left(  1+\frac{2n_{1}n_{2}}{n},
\frac{2n_{1}n_{2}(2n_{1}n_{2}-n)}{n^{2}(n-1)}\right)\]</span> siendo <span class="math inline">\(n_{1}\)</span> y <span class="math inline">\(n_{2}\)</span> el nº de signos <span class="math inline">\(+\)</span> y <span class="math inline">\(-\)</span> en la muestra, respectivamente (<span class="math inline">\(n_{1}+n_{2}=n\)</span>). Para tamaños muéstrales pequeños (<span class="math inline">\(n&lt;40\)</span>), esta aproximación no es buena y conviene utilizar la distribución exacta (o utilizar corrección por continuidad). Los valores críticos de esta distribución están tabulados.</p></li>
</ul>
<p>Este contraste se emplea también para variables continuas, se fija un punto de corte para dicotomizarlas. Normalmente se toma como punto de corte la mediana.</p>
<ul>
<li><p>En este caso si <span class="math inline">\(k=n_{1}\)</span> (<span class="math inline">\(\simeq n_{2}\)</span>): <span class="math display">\[R\underset{aprox.}{\sim}N\left(  k+1,\frac{k(k-1)}{2k-1}\right)\]</span></p></li>
<li><p>Se rechaza la hipótesis nula de aleatoriedad si el número de rachas es significativamente pequeño o grande.</p></li>
<li><p>Si el tamaño muestral es grande, el <span class="math inline">\(p\)</span>-valor será: <span class="math display">\[p \simeq 2 P\left( Z \geq \left\vert 
\frac{R-E(R)}{\sqrt{Var(R)}} \right\vert \right)\]</span></p></li>
<li><p>Comandos R: <code>tseries::runs.test(as.factor(x &gt; median(x)))</code></p></li>
</ul>
<p><strong>Ejemplo</strong></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(tseries)
<span class="kw">runs.test</span>(<span class="kw">as.factor</span>(datos <span class="op">&gt;</span><span class="st"> </span><span class="kw">median</span>(datos)))</code></pre></div>
<pre><code>## 
##  Runs Test
## 
## data:  as.factor(datos &gt; median(datos))
## Standard Normal = -0.4422, p-value = 0.6583
## alternative hypothesis: two.sided</code></pre>
<p>Alternativamente, para evitar el cálculo del punto de corte (la mediana), requerido para dicotomizar la variable continua, se podría emplear una modificación de este contraste, el denominado test de rachas ascendentes y descendentes, en el que se generan los valores <span class="math inline">\(+\)</span> y <span class="math inline">\(-\)</span> dependiendo de si el valor de la secuencia es mayor o menor que el anterior (ver e.g. Downham, 1970). Este contraste es más adecuado para generadores aleatorios.</p>
</div>
<div id="el-contraste-de-ljung-box" class="section level3">
<h3><span class="header-section-number">B.2.6</span> El contraste de Ljung-Box</h3>
<p>Es un test muy utilizado (en series de tiempo) para contrastar la hipótesis de independencia. Se contrasta la hipótesis nula de que las primeras <span class="math inline">\(m\)</span> autocorrelaciones son cero: <span class="math display">\[\left\{\begin{array}[c]{l}
    H_{0}:\rho_{1}=\rho_{2}=\ldots=\rho_{m}=0\\
    H_{1}:\rho_{i}\neq0\text{ para algún } i
\end{array}
\right.\]</span></p>
<ul>
<li><p>Se elige un <span class="math inline">\(m\)</span> tal que la estimación <span class="math inline">\(r(m)\)</span> de <span class="math inline">\(\rho_{m}=\rho(m)\)</span> sea “fiable” (e.g. <span class="math inline">\(10\log_{10}n\)</span>).</p></li>
<li><p>El estadístico del contraste: <span class="math display">\[Q=n(n+2)\sum_{k=1}^{m}\frac{r(k)^{2}}{n-k}\underset{aprox.}{\sim}\chi
_{m}^{2}\text{, si }H_{0}\text{ es cierta.}\]</span></p></li>
<li><p>Se rechaza <span class="math inline">\(H_{0}\)</span> si el valor observado es grande (<span class="math inline">\(Q\geq \chi_{m,1-\alpha}^{2}\)</span>): <span class="math display">\[p=P\left(  {\chi_{m}^{2}}\geq Q\right)\]</span></p></li>
<li><p>Comandos R:</p></li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">    <span class="kw">Box.test</span>(x, <span class="dt">type=</span>Ljung)
    <span class="kw">Box.test</span>(x, lag, <span class="dt">type=</span>Ljung)</code></pre></div>
<p><strong>Ejemplo</strong></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">Box.test</span>(datos, <span class="dt">type=</span><span class="st">&quot;Ljung&quot;</span>) <span class="co"># Contrasta si la primera autocorrelación es nula </span></code></pre></div>
<pre><code>## 
##  Box-Ljung test
## 
## data:  datos
## X-squared = 0.0078317, df = 1, p-value = 0.9295</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">Box.test</span>(datos, <span class="dt">lag=</span><span class="dv">5</span>, <span class="dt">type=</span><span class="st">&quot;Ljung&quot;</span>) <span class="co"># Contrasta si las 5 primeras autocorrelaciones son nulas</span></code></pre></div>
<pre><code>## 
##  Box-Ljung test
## 
## data:  datos
## X-squared = 1.2556, df = 5, p-value = 0.9394</code></pre>
<p>NOTA: Cuando se trabaja con residuos de un modelo lineal, para contrastar que la primera autocorrelación es cero, es preferible emplear el test de Durbin-Watson implementado en la función <code>dwtest()</code> del paquete <code>lmtest</code>.</p>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="5">
<li id="fn5"><p>En algunos campos, como en estadística espacial, en lugar del covariograma se suele emplear el semivariograma <span class="math inline">\(\gamma(k) = C(0) - C(k)\)</span>.<a href="diagnosis-de-la-independencia.html#fnref5">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="gof.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="contrastes-específicos-para-generadores-aleatorios.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rubenfcasal/simbook/edit/master/22-Bondad_ajuste_Aleatoriedad.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["Simulacion.pdf"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
